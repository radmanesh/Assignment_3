{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Word Embedding, RNN, Token Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With your environment activated int the terminal, run:\n",
    "```\n",
    "mamba env create -n cs5293-3 python=3.10\n",
    "pip install -r requirements.txt\n",
    "##Your VSCode may complain sometime you need to install ipykernel using the following commands. If not, then  just ignore this. \n",
    "#mamba install -n cs5293-3 ipykernel  --force-reinstall \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you have to submit two things:\n",
    "* (1) The whole folder with your code (not with .cache or your model checkpoints)\n",
    "* (2) A report to summarize what your experienments in part 2 and part 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Word Embedding (Total: 50)"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.1 History: Symbolic vs. Neural vs. Neuro-Symbolic (0' Please just read it)\n",
    "In the lecture 11-12, we introduced two ways to represent language: (1) Symbolic Representation (2) Neural Representation. The symbolic representation is based on various linguistic theories in language understanding Pyramid from Morphology, Syntax, Semantics, to Pragmatics.\n",
    "\n",
    "Historically, symbolic NLP dominated the early decades of the field, beginning in the 1950s and 1960s with rule-based machine translation systems such as the Georgetown-IBM experiment, and heavily influenced by Chomskys formal grammars. During the 1970s and 1980s, symbolic approaches flourished through hand-crafted grammars, logic-based formalisms, and knowledge representation systems such as semantic networks, frames, and ontologies. Pioneering systems like SHRDLU demonstrated how symbolic representations could connect language with reasoning in restricted domains, while projects such as WordNet, FrameNet, PropBank, and the Penn Treebank provided structured lexical knowledge resources, each addressing different layers of linguistic representation, respectively. \n",
    "\n",
    "### From WordNet to ImageNet\n",
    "WordNet (Miller, 1995) offered a large-scale lexical database organized around synonym sets and semantic relations such as hypernymy and meronymy, making it foundational for lexical semantics and ontology construction. FrameNet (Fillmore et al., 1997) encoded knowledge about semantic frames and the roles that words evoke, supporting work in semantic role labeling and event understanding. PropBank (Kingsbury & Palmer, 2002) extended this by providing predicate-argument structures annotated on text, giving a bridge between syntax and semantics for machine learning approaches. Finally, the Penn Treebank (Marcus et al., 1993) provided richly annotated syntactic parses, enabling the development and benchmarking of parsers and statistical models. Together, these resources represented a major milestone in symbolic NLP, offering explicit, interpretable linguistic knowledge that underpinned decades of research in parsing, semantic role labeling, and knowledge-driven applications.  WordNet not only served as a cornerstone for lexical semantics in symbolic NLP, but also laid the groundwork for resources beyond language. Notably, it became the foundation for ImageNet (Deng et al., 2009), where WordNets synset hierarchy was used to define over 20,000 object categories and organize millions of labeled images. ImageNet, in turn, became the catalyst for modern deep learning: the 2012 ImageNet Large Scale Visual Recognition Challenge (ILSVRC) was famously won by AlexNet, marking the breakthrough moment that triggered the deep learning revolution. In this way, we can trace a direct historical lineage from symbolic lexical resources like WordNet to the emergence of neural representation learning  illustrating that even todays most successful neural methods are deeply indebted to the symbolic traditions that preceded them.\n",
    "\n",
    "### From SHRDLU to ChatGPT: \"Wow Moment\" in NLP\n",
    "Terry Winograds pioneering work on SHRDLU in the 1970s demonstrated how natural language could be grounded in reasoning and action within a well-defined world. Although the system was limited to the blocks world, its integration of syntax, semantics, and logic-based inference set a template for how language understanding could be tied to structured reasoning. This vision continues to influence modern research: todays large language models may rely on statistical learning rather than handcrafted rules, but many of their most exciting applications  from tool use to step-by-step reasoning and planning  still deeply echo the principles Winograd introduced. In this sense, his symbolic framework still resonates as a conceptual foundation for the reasoning capabilities we now seek to realize at scale with LLMs. It integrated syntax, semantics, and reasoning in one system, demonstrating the potential of symbolic approaches to make language explainable and grounded. Just as SHRDLU was a landmark moment for symbolic NLP, ChatGPT represents the modern SHRDLU moment for neural NLP  a vivid public demonstration of conversational competence. The next SHRDLU moment, however, may lie in systems that move beyond surface-level fluency toward grounded, explainable, and trustworthy reasoning  perhaps through hybrid neuro-symbolic approaches that finally reconcile efficiency with interpretability. Let's see!\n",
    "\n",
    "By the 1980s and 1990s, symbolic methods matured into large-scale parsers, grammar formalisms (e.g., LFG, HPSG, CCG), discourse models, and expert systems, aiming to capture meaning with precise rules. \n",
    "However, they also revealed limitations: brittleness in handling ambiguity, domain transfer, and the high cost of manual rule engineering. These challenges eventually opened the door for statistical and neural methods, though symbolic representation remains foundational in areas like formal semantics, knowledge graphs, and explainable AI. Modern NLP often revisits symbolic traditions in hybrid systems, combining the interpretability of structured knowledge with the adaptability of neural models.\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributional Hypothesis and Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does ongchoi mean? You will guess the meaning when you see the context of its usage: \n",
    "* Ong choi is delicious sauted with garlic. \n",
    "* Ong choi is superb over rice\n",
    "* Ong choi leaves with salty sauces\n",
    "\n",
    "Because you already seen the following so you conclude that Ongchoi is leafy green like spinach, chard, or collard greens\n",
    "* spinach sauted with garlic over rice\n",
    "* Chard stems and leaves are delicious\n",
    "* Collard greens and other salty leafy greens\n",
    "\n",
    "We learned two kinds of vector representation: Sparse(TF-IDF) and Dense(Skipgram and CBOW). \n",
    "In this assignment, we will learn how to train word embedding with NGram, SkipGram, then please implement your own Continuous Bag-of-Words(CBOW) via pytorch and related libaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.2. Train WordEmbedding via Neural Ngram Language Model(50')\n",
    "Before we go in depth, let us do a few quick notes\n",
    "about how to use embeddings in Pytorch and a further practice of Pytorch programming\n",
    "in general. Similar to how we defined a unique index for each word when\n",
    "making one-hot vectors in the Sparse vector representatio(Word-Term, Word-Word matrix), we also need to define an index for each word\n",
    "when using embeddings. These will be keys into a lookup table. That is,\n",
    "embeddings are stored as a $|V| \\times D$ matrix, where $D$ is the\n",
    "dimensionality of the embeddings, such that the word assigned index $i$\n",
    "has its embedding stored in the $i$\\'th row of the matrix. In all of my\n",
    "code, the mapping from words to indices is a dictionary named\n",
    "word\\_to\\_ix.\n",
    "\n",
    "The module that allows you to use embeddings is torch.nn.Embedding,\n",
    "which takes two arguments: the vocabulary size, and the dimensionality\n",
    "of the embeddings.\n",
    "\n",
    "To index into this table, you must use torch.LongTensor (since the\n",
    "indices are integers, not floats)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6614,  0.2669,  0.0617,  0.6213, -0.4519]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n",
      "torch.Size([1]) torch.int64\n",
      "torch.Size([1, 5]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "# set a seed\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# Let us assume a simple key-value dictionary to map each words into an index.\n",
    "word_to_ix = {\"hello\": 0, \"world\": 1}\n",
    "# Then we define a simple embedding layer in Pytorch\n",
    "embeds = nn.Embedding(2, 5)  # 2 words in vocab, 5 dimensional embeddings\n",
    "# We look up the embedding layer via the word indices.\n",
    "lookup_tensor = torch.tensor([word_to_ix[\"hello\"]], dtype=torch.long)\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print(hello_embed)\n",
    "# Print the shape and type of the lookup tensor and the embedding\n",
    "print(lookup_tensor.shape, lookup_tensor.dtype)\n",
    "print(hello_embed.shape, hello_embed.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14921 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Let use the glove embedding in the data folder and load it via pytorch\n",
    "import numpy as np\n",
    "embeddings_index = {}\n",
    "with open(\"../data/glove.6B.50d-subset.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   14921 ../data/glove.6B.50d-subset.txt\n"
     ]
    }
   ],
   "source": [
    "# Using a linux command to check how many lines in the glove.6B.50d-subset.txt\n",
    "# It matches the number of word vectors we just loaded.\n",
    "!wc -l ../data/glove.6B.50d-subset.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another Pytorch Tutorial: Neural Network N-Gram Language Modeling (30')\n",
    "\n",
    "Recall that in an n-gram language model, given a sequence of words $w$,\n",
    "we want to compute\n",
    "\n",
    "$$P(w_i | w_{i-1}, w_{i-2}, \\dots, w_{i-n+1} )$$\n",
    "\n",
    "Where $w_i$ is the ith word of the sequence.\n",
    "\n",
    "In this example, different from SkipGram, we will use the previous n words to predict the next words as the self-supervised learning. \n",
    "In the following example, we still use the Markov Assumption, ngram model, to train our word embeddings. \n",
    "\n",
    "Actually, this left-to-right autogressive way of next word prediction is also the way ChatGPT get pretrained nowadays except that OpenAI have different instruction data and more reward/preference data for the post-training part. Furthermore, they have much longer context\n",
    "\n",
    "Based on next word prediction Ngram model, we will compute the loss function on some training examples and update the parameters with backpropagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different the count-based N-gram in assignment1, here we will build a\n",
    "# neural network based N-gram model. The input to the model is the\n",
    "# concatenation of the embeddings of the context words, and the output\n",
    "# is the log-probabilities of the words in the vocabulary.\n",
    "# We will use a simple feed-forward neural network with one hidden layer.\n",
    "# The hidden layer has 128 units and uses the ReLU activation function.\n",
    "# The output layer uses the log-softmax function to produce log-probabilities.\n",
    "# The loss function is the negative log-likelihood loss given the log-probabilities\n",
    "# and the target word.\n",
    "\n",
    "class NGramLanguageModeler(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModeler, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        # the last layer to predict the log-probability of each word in the vocabulary\n",
    "        # You could image this layer as a classifier over the vocabulary, which is |V|-wasy classifier.\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out, dim=1)\n",
    "        return log_probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bigram, the context size is 1\n",
    "# For trigram, the context size is 2, let us use the trigram for this example.\n",
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "# We will use Shakespeare Sonnet 2\n",
    "test_sentence = \"\"\"When forty winters shall besiege thy brow,\n",
    "And dig deep trenches in thy beauty's field,\n",
    "Thy youth's proud livery so gazed on now,\n",
    "Will be a totter'd weed of small worth held:\n",
    "Then being asked, where all thy beauty lies,\n",
    "Where all the treasure of thy lusty days;\n",
    "To say, within thine own deep sunken eyes,\n",
    "Were an all-eating shame, and thriftless praise.\n",
    "How much more praise deserv'd thy beauty's use,\n",
    "If thou couldst answer 'This fair child of mine\n",
    "Shall sum my count, and make my old excuse,'\n",
    "Proving his beauty by succession thine!\n",
    "This were to be new made when thou art old,\n",
    "And see thy blood warm when thou feel'st it cold.\"\"\".split()\n",
    "\n",
    "# we should tokenize the input, but we will ignore that for now\n",
    "# build a list of tuples.\n",
    "# Each tuple is ([ word_i-CONTEXT_SIZE, ..., word_i-1 ], target word)\n",
    "# please padding the context with <s> if there is no enough context\n",
    "# for example, the first tuple would be ([\"<s>\", \"<s>\"], \"When\")\n",
    "# the second tuple would be ([\"<s>\", \"When\"], \"forty\")\n",
    "# and so on.\n",
    "# Note that we are using the previous CONTEXT_SIZE words to predict the next word.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['<s>', '<s>'], 'When'), (['<s>', 'When'], 'forty'), (['When', 'forty'], 'winters')]\n",
      "Vocab size: 98\n"
     ]
    }
   ],
   "source": [
    "# A function to extract the ngrams from the test_sentence\n",
    "def extract_ngrams(context_size, test_sentence):\n",
    "    # always pad the context with <s>\n",
    "    # for example, the first tuple would be ([\"<s>\", \"<s>\"], \"When\")\n",
    "    # the second tuple would be ([\"<s>\", \"When\"], \"forty\")\n",
    "    # and so on.\n",
    "    # Note that we are using the previous CONTEXT_SIZE words to predict the next word.\n",
    "    # please padding the context with <s> if there is no enough context\n",
    "    # preappend <s> * context_size to the test_sentence\n",
    "    padded_sentence = [\"<s>\"] * context_size + test_sentence\n",
    "    ngrams = [\n",
    "        (padded_sentence[i - context_size:i], padded_sentence[i])\n",
    "        for i in range(context_size, len(padded_sentence))\n",
    "    ]\n",
    "    return ngrams\n",
    "\n",
    "ngrams = extract_ngrams(CONTEXT_SIZE, test_sentence)\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(ngrams[:3])\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "vocab.add(\"<s>\")\n",
    "vocab = list(vocab)\n",
    "# print the vocab size\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "# build up the word to index dictionary for all the words in the vocab, including <s>\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGramLanguageModeler(\n",
      "  (embeddings): Embedding(98, 10)\n",
      "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=98, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# use print to visualize the model we just built\n",
    "print(model)\n",
    "# Notice that we didn't put the relu into the model definition, because it has no parameters.\n",
    "# We will move the relu into the model definition later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385355\n"
     ]
    }
   ],
   "source": [
    "# Analyze the number of trainable parameters in the model\n",
    "trainable_params = sum(\n",
    "\tp.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "\n",
    "print(trainable_params)\n",
    "assert trainable_params == (len(vocab) * EMBEDDING_DIM) + (CONTEXT_SIZE * EMBEDDING_DIM * 128) + 128 + (128 * len(vocab)) + len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the NNLM(5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 525.8715076446533\n",
      "Epoch 2, Loss: 523.370274066925\n",
      "Epoch 3, Loss: 520.8853225708008\n",
      "Epoch 4, Loss: 518.4166378974915\n",
      "Epoch 5, Loss: 515.963339805603\n",
      "Epoch 6, Loss: 513.5233128070831\n",
      "Epoch 7, Loss: 511.0958275794983\n",
      "Epoch 8, Loss: 508.6792848110199\n",
      "Epoch 9, Loss: 506.2722725868225\n",
      "Epoch 10, Loss: 503.87573432922363\n",
      "tensor([ 1.3009, -0.6289, -0.0693,  0.6943, -0.2894,  0.1512, -0.2991, -0.1297,\n",
      "         1.5375,  0.9191], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Finish the training code below\n",
    "# We will train the model using the ngrams we just extracted\n",
    "# The training code is similar to the one we used in the Assignment 2\n",
    "def train_model(model, ngrams, word_to_ix, loss_function, optimizer, epochs=10):\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        # Step through the training data one context-target pair at a time\n",
    "        # We will change this to mini-batch later\n",
    "        # shuffle the ngrams for each epoch\n",
    "        import random\n",
    "        random.shuffle(ngrams)\n",
    "        for context, target in ngrams:\n",
    "            # !! Fix the code below !!\n",
    "            # Step 1. Prepare the inputs to be passed to the model (i.e., turn the words\n",
    "            # into integer indices and wrap them in tensors)\n",
    "            # Hint: Use word_to_ix to map words to indices\n",
    "            context_idxs = [word_to_ix[w] for w in context]\n",
    "            target_idx = word_to_ix[target]\n",
    "            # Finish the following line\n",
    "            # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "            # new instance, you need to zero out the gradients from the old\n",
    "            # instance\n",
    "            optimizer.zero_grad()\n",
    "            context_tensor = torch.tensor(context_idxs, dtype=torch.long)\n",
    "            target_tensor = torch.tensor([target_idx], dtype=torch.long)\n",
    "            # Step 3. Run the forward pass, getting log probabilities over next words\n",
    "            log_probs = model(context_tensor)\n",
    "            # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "            # word wrapped in a tensor)\n",
    "            loss = loss_function(log_probs, target_tensor)\n",
    "            # Step 5. Do the backward pass and update the gradient\n",
    "            # Hint: caculate the loss, call loss.backward(), and then call optimizer.step()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # Get the Python number from a 1-element Tensor by calling tensor.item()\n",
    "            total_loss += loss.item()\n",
    "        losses.append(total_loss)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n",
    "    return losses\n",
    "\n",
    "# Train the model using the train_model function\n",
    "losses = train_model(model, ngrams, word_to_ix, loss_function, optimizer)\n",
    "\n",
    "# To get the embedding of a particular word, e.g., \"beauty\"\n",
    "print(model.embeddings.weight[word_to_ix[\"beauty\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let use the training file in assignment 1 to rebuild this Neural Ngram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"In college football action , the University of Donald Trump's Fighting Donald Trumps wins the national championship in the Donald Trump Bowl by purchasing a last-second field goal for a reported $ 23 million . \\n\", 'The savings and loan industry announces heavy fourth-quarter bingo losses . \\n', 'President Bush is sworn in and declares a War on Trout . \\n']\n"
     ]
    }
   ],
   "source": [
    "# Reading the lines from training file in assignment 1\n",
    "with open(\"../data/training.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "# Just print the first 3 lines to see how it looks like\n",
    "print(lines[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['<s>', '<s>'], 'in'), (['<s>', 'in'], 'college'), (['in', 'college'], 'football')]\n",
      "Vocabulary size: 2752\n",
      "add <s>, vocabulary size: 2753\n"
     ]
    }
   ],
   "source": [
    "# Generate ngrams from the training file\n",
    "# We will simply split the lines into words via whitespace\n",
    "# and use a context size of 2 to build the trigrams.\n",
    "# Let us assume a simple key-value dictionary to map each words into an index.\n",
    "# Let us ignore case of the words, the starting and ending tokens for each line for now.\n",
    "CONTEXT_SIZE = 2\n",
    "EMBEDDING_DIM = 10\n",
    "\n",
    "ngrams = [] # list of tuples\n",
    "vocab = set()\n",
    "# Just split the lines into words via whitespace\n",
    "# and use a context size of 2 to build the trigrams.\n",
    "# Let us ignore case of the words, still padding with <s>.\n",
    "# generate the ngrams for each line and add them to the ngrams list\n",
    "# add the words to the vocab set\n",
    "for line in lines:\n",
    "    words = line.lower().strip().split()\n",
    "    vocab.update(words)\n",
    "    ngrams.extend(extract_ngrams(CONTEXT_SIZE, words))\n",
    "\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(ngrams[:3])\n",
    "# Print the vocabulary size, which should be larger than the sonnet example.\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "# It should be same as the number in your assignment 1. It is 2752 because we use the same training file.\n",
    "# However, here we also add the <s> token to the vocab, because this <s> token also has a trainable embedding.\n",
    "vocab.add(\"<s>\")\n",
    "vocab = list(vocab)\n",
    "print(\"add <s>, vocabulary size:\", len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "385355\n",
      "Epoch 1, Loss: 83558.9421185255\n",
      "Epoch 2, Loss: 76330.00425708294\n",
      "Epoch 3, Loss: 73618.41957342625\n",
      "Epoch 4, Loss: 72110.80289721489\n",
      "Epoch 5, Loss: 71081.50876891613\n",
      "Epoch 6, Loss: 70295.92829072475\n",
      "Epoch 7, Loss: 69634.85490322113\n",
      "Epoch 8, Loss: 69053.30780541897\n",
      "Epoch 9, Loss: 68519.6286200285\n",
      "Epoch 10, Loss: 68019.64773821831\n"
     ]
    }
   ],
   "source": [
    "# Let use the above ngrames and vocab to train a neural ngram LM\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "# Enter your code here to train the model\n",
    "# You can use the same training loop as above\n",
    "losses = []\n",
    "# Let use the above ngrames and vocab to train a neural ngram LM\n",
    "# Since the output is a log-probability over the vocabulary, we can use\n",
    "# the negative log likelihood loss.\n",
    "# If you are not familiar with it, you can read about it here:\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.NLLLoss.html\n",
    "loss_function = nn.NLLLoss()\n",
    "model = NGramLanguageModeler(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "# analyze the number of trainable parameters in the model\n",
    "trainable_params = sum(\n",
    "\tp.numel() for p in model.parameters() if p.requires_grad\n",
    ")\n",
    "print(trainable_params)\n",
    "assert trainable_params == (len(vocab) * EMBEDDING_DIM) + (CONTEXT_SIZE * EMBEDDING_DIM * 128) + 128 + (128 * len(vocab)) + len(vocab)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "# call the train_model function to train the model\n",
    "# Note that this will take a while, since we are not using mini-batch\n",
    "# So please use a smaller number of epochs, e.g., < 10\n",
    "losses = train_model(model, ngrams, word_to_ix, loss_function, optimizer, epochs=10)\n",
    "# You should see the loss decreasing over epochs. This is a good sign.\n",
    "# You can plot the loss over epochs if you like.\n",
    "# You can use matplotlib to plot the loss.\n",
    "# import matplotlib.pyplot as plt\n",
    "# plt.plot(losses)\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.show()\n",
    "# However, the loss is not very meaningful since we do not have a\n",
    "# held-out validation set. We will ignore that for now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batch Training with Batch NLLM Model(5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To stable the training, you can try to tune the learning rate and write a mini-batch version of the training loop.\n",
    "# You can use the torch.utils.data.DataLoader to create mini-batches.\n",
    "# You can read about it here:\n",
    "# https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "# Implement a mini-batch version of the training loop here with the DataLoader.\n",
    "\n",
    "def train_model_mini_batch(model, ngrams, word_to_ix, loss_function, optimizer, epochs=10, batch_size=32):\n",
    "    from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "    # Prepare the dataset\n",
    "    contexts = []\n",
    "    targets = []\n",
    "    for context, target in ngrams:\n",
    "        context_idxs = [word_to_ix[w] for w in context]\n",
    "        target_idx = word_to_ix[target]\n",
    "        contexts.append(context_idxs)\n",
    "        targets.append(target_idx)\n",
    "\n",
    "    # Convert to tensors\n",
    "    contexts_tensor = torch.tensor(contexts, dtype=torch.long)\n",
    "    targets_tensor = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    # Create DataLoader for mini-batch training\n",
    "    dataset = TensorDataset(contexts_tensor, targets_tensor)\n",
    "    # shuffle and batch the data at each epoch\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        # Step through the training data one batch at a time\n",
    "        # We will use mini-batch training\n",
    "        # Each batch contains batch_size context-target pairs\n",
    "        # We will use the DataLoader to create mini-batches\n",
    "        for context_batch, target_batch in dataloader:\n",
    "            ## !! Fix the code below !!\n",
    "            optimizer.zero_grad()\n",
    "            log_probs = model(context_batch)\n",
    "            loss = loss_function(log_probs, target_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        losses.append(total_loss)\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss}\")\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a mini-batch version of the NGramLanguageModeler forward function\n",
    "class NGramLanguageModelerBatch(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(NGramLanguageModelerBatch, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 128)\n",
    "        self.linear2 = nn.Linear(128, vocab_size)\n",
    "        # instead of call F.relu in the forward function, we can use nn.ReLU in the constructor and put it into a nn.Sequential\n",
    "        self.relu = nn.ReLU()\n",
    "        # instead of call F.log_softmax in the forward function, we can use nn.LogSoftmax in the constructor and put it into a nn.Sequential\n",
    "        # Note that we need to specify the dimension to apply log_softmax\n",
    "        # nn.Flatten is used to flatten the input tensor, see more details here:\n",
    "        # https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html\n",
    "        self.model = nn.Sequential(\n",
    "            self.embeddings,\n",
    "            nn.Flatten(),\n",
    "            self.linear1,\n",
    "            self.relu,\n",
    "            self.linear2,\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # inputs is of shape (batch_size, context_size)\n",
    "        # each row is a context\n",
    "        # we can pass the inputs directly to the self.model\n",
    "        # because the self.model contains all the layers we need\n",
    "        log_probs = self.model(inputs)\n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGramLanguageModelerBatch(\n",
      "  (embeddings): Embedding(2753, 10)\n",
      "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
      "  (linear2): Linear(in_features=128, out_features=2753, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (model): Sequential(\n",
      "    (0): Embedding(2753, 10)\n",
      "    (1): Flatten(start_dim=1, end_dim=-1)\n",
      "    (2): Linear(in_features=20, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=128, out_features=2753, bias=True)\n",
      "    (5): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n",
      "385355\n",
      "Epoch 1, Loss: 2760.3039932250977\n",
      "Epoch 2, Loss: 2634.208804130554\n",
      "Epoch 3, Loss: 2519.3513164520264\n",
      "Epoch 4, Loss: 2446.484270095825\n",
      "Epoch 5, Loss: 2398.211813926697\n",
      "Epoch 6, Loss: 2361.980938911438\n",
      "Epoch 7, Loss: 2332.273838996887\n",
      "Epoch 8, Loss: 2307.594515800476\n",
      "Epoch 9, Loss: 2290.5953454971313\n",
      "Epoch 10, Loss: 2273.725051879883\n"
     ]
    }
   ],
   "source": [
    "# let use the mini-batch model to train the model\n",
    "batch_model = NGramLanguageModelerBatch(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "batch_optimizer = optim.SGD(batch_model.parameters(), lr=0.01)\n",
    "\n",
    "# let us print the new model\n",
    "print(batch_model)\n",
    "# analyze the number of trainable parameters in the new model\n",
    "trainable_params = sum(\n",
    "    p.numel() for p in batch_model.parameters() if p.requires_grad\n",
    ")\n",
    "print(trainable_params)\n",
    "assert trainable_params == (len(vocab) * EMBEDDING_DIM) + (CONTEXT_SIZE * EMBEDDING_DIM * 128) + 128 + (128 * len(vocab)) + len(vocab)\n",
    "# call the train_model_mini_batch function to train the model, this should be much faster than the previous one\n",
    "losses = train_model_mini_batch(batch_model, ngrams, word_to_ix, loss_function, batch_optimizer, epochs=10, batch_size=32)\n",
    "# You should see the loss decreasing over epochs. This is a good sign.\n",
    "# You can plot the loss over epochs if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      good:tensor([-0.1038, -1.6306,  1.2916,  0.6565, -0.5886, -0.9817,  0.0465,  0.6765,\n",
      "         0.0829,  0.4262], grad_fn=<SelectBackward0>)\n",
      "      nice:tensor([-1.7619,  0.6791, -0.8561,  1.0270,  0.3578, -0.1685, -1.3243, -0.8351,\n",
      "         1.2460, -1.0553], grad_fn=<SelectBackward0>)\n",
      "      bad:tensor([ 1.6047,  0.3733, -0.5451,  1.2561, -1.4682, -1.0815, -1.2800,  0.7112,\n",
      "        -0.1925, -0.3703], grad_fn=<SelectBackward0>)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# To get the embedding of a particular word, e.g. \"good\", \"nice\", and \"bad\"\n",
    "good_embedding = batch_model.embeddings.weight[word_to_ix[\"good\"]]\n",
    "nice_embedding = batch_model.embeddings.weight[word_to_ix[\"nice\"]]\n",
    "bad_embedding = batch_model.embeddings.weight[word_to_ix[\"bad\"]]\n",
    "print(f\"\"\"\n",
    "      good:{good_embedding}\n",
    "      nice:{nice_embedding}\n",
    "      bad:{bad_embedding}\n",
    "    \"\"\"\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the Word Embedding (5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distances between 'good' and 'nice': Cosine: -0.2807936668395996, Euclidean: 4.701253890991211, Manhattan: 13.772335052490234\n",
      "Distances between 'good' and 'bad': Cosine: 0.18308570981025696, Euclidean: 3.731238603591919, Manhattan: 9.561213493347168\n",
      "Distances between 'nice' and 'bad': Cosine: 0.008831620216369629, Euclidean: 4.547056198120117, Manhattan: 10.665542602539062\n"
     ]
    }
   ],
   "source": [
    "# Let measure the distance between these embeddings via cosine similarity, euclidean distance, and manhattan distance\n",
    "# write the code to compute these distances\n",
    "def compute_all_distances(emb1, emb2):\n",
    "\tcos = F.cosine_similarity(emb1.unsqueeze(0), emb2.unsqueeze(0)).item()\n",
    "\teuclidean_distance = torch.dist(emb1, emb2, p=2).item()\n",
    "\tmanhattan_distance = torch.dist(emb1, emb2, p=1).item()\n",
    "\treturn cos, euclidean_distance, manhattan_distance\n",
    "\n",
    "# test three words that are synonyms or antonyms\n",
    "def test_distances(model):\n",
    "    word_pairs = [(\"good\", \"nice\"), (\"good\", \"bad\"), (\"nice\", \"bad\")]\n",
    "    for w1, w2 in word_pairs:\n",
    "        emb1 = model.embeddings.weight[word_to_ix[w1]]\n",
    "        emb2 = model.embeddings.weight[word_to_ix[w2]]\n",
    "        cos, euclidean_distance, manhattan_distance = compute_all_distances(emb1, emb2)\n",
    "        print(f\"Distances between '{w1}' and '{w2}': Cosine: {cos}, Euclidean: {euclidean_distance}, Manhattan: {manhattan_distance}\")\n",
    "\n",
    "test_distances(batch_model)\n",
    "\n",
    "# You will find that the trained embedding may not very good when using 2 and 50, please try to use a larger context size and embedding dimension to improve it in Task 1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NGramLanguageModelerBatch(\n",
       "  (embeddings): Embedding(2753, 10)\n",
       "  (linear1): Linear(in_features=20, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=2753, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (model): Sequential(\n",
       "    (0): Embedding(2753, 10)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=20, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=2753, bias=True)\n",
       "    (5): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model with torch.save\n",
    "torch.save(batch_model.state_dict(), \"ngram_model.pth\")\n",
    "\n",
    "# However, the state_dict only contains the parameters of the model, not the words_to_ix dictionary or idx_to_word dictionary.\n",
    "# You need to save them separately if you want to use the model later.\n",
    "import pickle\n",
    "with open(\"word_to_ix.pkl\", \"wb\") as f:\n",
    "    pickle.dump(word_to_ix, f)\n",
    "with open(\"vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "# However, the saved model only contains the parameters of the model, not the model structure.\n",
    "# To load the model, you need to create a new instance of the model class\n",
    "\n",
    "# load the model with torch.load\n",
    "# you need to create a new model instance first\n",
    "loaded_model = NGramLanguageModelerBatch(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "loaded_model.load_state_dict(torch.load(\"ngram_model.pth\"))\n",
    "loaded_model.eval()  # set the model to evaluation mode\n",
    "# Now you can use the loaded_model to do inference or further training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caculate N-gram Probability with NN Model (10')\n",
    "\n",
    "Instead of using the count-based Ngram, let use the probability of 3-gram model from the NN we just trained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 2753\n",
      "Sentence: Wolf\n",
      "Log-Probability: -8.603910446166992\n",
      "\n",
      "Sentence: Widespread panic\n",
      "Log-Probability: -17.472312927246094\n",
      "\n",
      "Sentence: I don't trust horses .\n",
      "Log-Probability: -28.55367159843445\n",
      "\n",
      "Sentence: I swear I am not making this up .\n",
      "Log-Probability: -51.78269004821777\n",
      "\n",
      "Sentence: Never forget your froggy .\n",
      "Log-Probability: -35.943697929382324\n",
      "\n",
      "Sentence: Little did I know that a treacherous lizard addressed 300,000 scientists .\n",
      "Log-Probability: -82.95192766189575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the log-probability of a sentence using the trained neural n-gram model\n",
    "def sentence_log_probability(model, sentence, word_to_ix, context_size=2):\n",
    "    \"\"\"\n",
    "    Calculate the total log-probability of a sentence by summing log-probabilities\n",
    "    of each word given its context.\n",
    "\n",
    "    Args:\n",
    "        model: Trained NGramLanguageModelerBatch neural network\n",
    "        sentence: Input sentence as a string\n",
    "        word_to_ix: Dictionary mapping words to their integer indices\n",
    "        context_size: Number of previous words to use as context (default=2 for trigram)\n",
    "\n",
    "    Returns:\n",
    "        log_prob: Total log-probability of the sentence (float)\n",
    "    \"\"\"\n",
    "    # Convert sentence to lowercase and split into words\n",
    "    words = sentence.lower().strip().split()\n",
    "    # Pad the beginning with <s> tokens to handle the first few words\n",
    "    # e.g., for trigram: [\"<s>\", \"<s>\", \"word1\", \"word2\", ...]\n",
    "    padded_sentence = [\"<s>\"] * context_size + words\n",
    "    # Initialize cumulative log probability\n",
    "    log_prob = 0.0\n",
    "\n",
    "    # Iterate through each word position (starting after the padding)\n",
    "    for i in range(context_size, len(padded_sentence)):\n",
    "        # Extract the context: previous context_size words\n",
    "        # e.g., for i=2, context_size=2: padded_sentence[0:2]\n",
    "        context = padded_sentence[i - context_size:i]\n",
    "        # The target word to predict at position i\n",
    "        target = padded_sentence[i]\n",
    "        # Convert context words to their indices (use <s> for unknown words)\n",
    "        context_idxs = [word_to_ix.get(w, word_to_ix[\"<s>\"]) for w in context]\n",
    "        # Convert target word to its index (use <s> for unknown words)\n",
    "        target_idx = word_to_ix.get(target, word_to_ix[\"<s>\"])\n",
    "        # Convert context indices to a tensor and add batch dimension\n",
    "        # Shape changes from (context_size,) to (1, context_size) for batch processing\n",
    "        context_tensor = torch.tensor([context_idxs], dtype=torch.long)\n",
    "        # Get log-probabilities from the model for all vocabulary words\n",
    "        # log_probs shape: (1, vocab_size)\n",
    "        log_probs = model(context_tensor)\n",
    "        # Extract the log-probability of the target word and accumulate\n",
    "        # log_probs[0, target_idx] gets the probability at batch index 0, word index target_idx\n",
    "        log_prob += log_probs[0, target_idx].item()\n",
    "\n",
    "    # Return the total log-probability of the sentence\n",
    "    return log_prob\n",
    "\n",
    "# Read test sentences from the test file used in assignment 1\n",
    "with open(\"../data/test.txt\", \"r\") as f:\n",
    "    test_lines = f.readlines()  # List of test sentences\n",
    "\n",
    "# Load the vocabulary from the saved pickle file\n",
    "vocab = pickle.load(open(\"vocab.pkl\", \"rb\"))  # List of all vocabulary words\n",
    "# Create reverse mapping from indices to words\n",
    "ix_to_word = {i: w for i, w in enumerate(vocab)}\n",
    "# Print and verify vocabulary size matches the model's embedding layer\n",
    "print(\"Vocab size:\", len(vocab))\n",
    "assert len(vocab) == len(loaded_model.embeddings.weight)\n",
    "# Load the word-to-index mapping from the saved pickle file\n",
    "word_to_ix = pickle.load(open(\"word_to_ix.pkl\", \"rb\"))  # Dictionary: word -> index\n",
    "# Calculate and print log-probability for each test sentence\n",
    "for line in test_lines:\n",
    "    # Calculate log-probability for the current sentence\n",
    "    log_prob = sentence_log_probability(loaded_model, line.strip(), word_to_ix)\n",
    "    # Print the sentence and its log-probability\n",
    "    print(f\"Sentence: {line.strip()}\\nLog-Probability: {log_prob}\\n\")\n",
    "\n",
    "# Compare the log-probability of the sentences in the test file with the one you got in assignment 1.\n",
    "# Of course it will be different, since we are using a different model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate a text with NNLM and Learned Word Embeddings (5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: I\n",
      "Generated: to and , the , , and , a .\n",
      "\n",
      "Seed: the\n",
      "Generated: .\n",
      "\n",
      "Seed: according\n",
      "Generated: i to the the is a that .\n",
      "\n",
      "Seed: animals\n",
      "Generated: , to to of the that , the , , is the of , the on the to , and .\n",
      "\n",
      "Seed: Zsa\n",
      "Generated: a in , in the i , and , .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally, let use the own neural ngram language model to generate some text as the generator in assignment 1\n",
    "# We will use the model to generate text given a starting context\n",
    "# * your program generates one of three words: [. ? !]\n",
    "# * your program generates 40 words (NOT including the original seed word)\n",
    "# We will use the similar sampling method as in assignment 1\n",
    "# However, instead of sampling from the count-based distribution, we will sample from the log-probability distribution\n",
    "# We will use the torch.multinomial function to sample from the distribution\n",
    "# You can read about it here: https://pytorch.org/docs/stable/generated/torch.multinomial.html\n",
    "# Note that the input to torch.multinomial should be a probability distribution\n",
    "# So we need to exponentiate the log-probabilities to get the probabilities\n",
    "# We will also use the torch.topk function to get the top k words with highest probabilities\n",
    "# You can read about it here: https://pytorch.org/docs/stable/generated/torch.topk.html\n",
    "# This is to avoid sampling from the entire vocabulary, which may include many low-probability words\n",
    "# We will set k = 10 by default\n",
    "# You can adjust the k value to see how it affects the generation\n",
    "# You can also adjust the max_len value to see how it affects the generation\n",
    "# We will learn more parameters to control the generation in the next assignment\n",
    "def generate_text(model, start_words, word_to_ix, ix_to_word, context_size=2, max_len=40, k=10):\n",
    "    model.eval()  # set the model to evaluation mode\n",
    "    words = start_words.lower().split()\n",
    "    if len(words) < context_size:\n",
    "        words = [\"<s>\"] * (context_size - len(words)) + words\n",
    "\n",
    "    generated_words = words[:] # start with the initial context words\n",
    "    for _ in range(max_len):\n",
    "        context = generated_words[-context_size:]  # get the last context_size words\n",
    "        context_idxs = [word_to_ix.get(w, word_to_ix[\"<s>\"]) for w in context]\n",
    "        context_tensor = torch.tensor([context_idxs], dtype=torch.long)\n",
    "        log_probs = model(context_tensor)\n",
    "        probs = torch.exp(log_probs).squeeze()  # convert log-probs to probs and remove batch dimension\n",
    "        topk_probs, topk_indices = torch.topk(probs, k)  # get top k probabilities and their indices\n",
    "        topk_probs = topk_probs / torch.sum(topk_probs)  # normalize to get a valid probability distribution\n",
    "        next_word_idx = torch.multinomial(topk_probs, 1).item()  # sample one index from the top k\n",
    "        next_word = ix_to_word[topk_indices[next_word_idx].item()]  # get the corresponding word\n",
    "        generated_words.append(next_word)\n",
    "        if next_word in {\".\", \"?\", \"!\"}:  # stop if we generate a sentence-ending punctuation\n",
    "            break\n",
    "    return ' '.join(generated_words[context_size:])  # return the generated words excluding the initial <s> tokens\n",
    "\n",
    "# let us read the seed words from the seed file in assignment 1, and start the generation\n",
    "with open(\"../data/seeds.txt\", \"r\") as f:\n",
    "    seed_lines = f.readlines()\n",
    "\n",
    "# start the generation\n",
    "ix_to_word = {i: w for w, i in word_to_ix.items()}\n",
    "for line in seed_lines:\n",
    "    generated_text = generate_text(loaded_model, line.strip(), word_to_ix, ix_to_word)\n",
    "    print(f\"Seed: {line.strip()}\\nGenerated: {generated_text}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Futher Exploration on WordEmbedding via OSCER (20')\n",
    "You will find that the trained embedding is not very good. For example, sometimes the \"good\" is opposite with \"nice\"(negative cos similarity) but has positive cos similarity with \"bad\". \n",
    "\n",
    "** Important: Please write a pdf to report your improvement with the following improvement **\n",
    "\n",
    "Please put the useful code into a seperate file called \"nnlm.py\" to run other experiments for improvement, such as \"context = 5, dimension = 50\", also adjust the learning rate etc, see how to improve this. \n",
    "* Please make it work the similar as the ngram.py in the assignment 1 Part2 to caculate the probability and generate the sentences. It will take traningfile, test_file and seed_file as input, and any other arguments, caculate the probability, and generate the text.\n",
    "    * Input and Command:```python nnlm.py <training file> <test file> <seeds_file>```\n",
    "    * Output: Two trace files: (1) ngram-prob.trace for the logprob outputs (2) ngram-gen.trace for the generated sentence for each seed.\n",
    "* Please run this new program with sbatch in OSCER to test different hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Deep Neural Network with Word Embedding for Sentiment Classification (Total: 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Assignment 2, you have worked on a 5-way deep average network on sentiment dataset (SST-5), which has 5 labels: very positive, positive, neutral, negative, very negative.  However, the performance is realtive low. \n",
    "\n",
    "In this part, based on the same SST-5 dataset, you have two tasks to test models beyond manually crafted features, let us move on the pretrained word embeddings. How well the word embedding based classifcation performed on sentiment classification. \n",
    "\n",
    "\n",
    "Important Hints:\n",
    "\n",
    "* Note that there will be some out of vocabulary word.\n",
    "* You will find a ton of existing code for this two tasks, it is ok to refer or reuse some of those code. \n",
    "* But some of those code are too old. You SHOULD use the lastest stable pytorch(2.8.0) for this.\n",
    "* To run a batch job on OSCER, you need to reassemble the code from the notebook into regular source code to submit a slurm job (as we asked in this Part 1 NNLM)\n",
    "\n",
    "What to turn in: You need to turn in the code and a pdf report to show the performance of your two new models on SST-5 dataset.\n",
    "* Your hyperparameters, Model Architecture, the size of each layer, which word embedding\n",
    "* Performance Metrics\n",
    "Performance Metrics: \n",
    "* Classification Report in Sklearn (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "* Confusion Matrix (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.1 Deep Averaging Networks(10')\n",
    " Improve the performance on SST-5(Assignment-2) with Word Embedding and Deep Averaging Networks as we mentioned in the class. Please implement a new pytorch model upon your Assignment-2' code base (But feel free to restart from scratch according to the tutorial in Part 1).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.2 Pytorch LSTM (20')\n",
    "Your goal: Add a new pytorch model(nn.module) using the 1-layer LSTM module for your SST-5 sentiment classifier in assignment 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: There are tons of tutorial of using pytorch LSTM, even for this SST-5 dataset...\n",
    "1. https://colab.research.google.com/gist/SauravMaheshkar/168f0817f0cd29dd4048868fb0dd4401/lstms-in-pytorch.ipynb#scrollTo=BKAA2rR0-B-3  This also introduce the code how to use wandb to track your experiments, which will be very useful for your project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2.3 Using Gensim to Train a Word Embedding(20')\n",
    "\n",
    "We have learned SkipGram in our class. With the above pytorch tutorial on NNLM(Part 1), it should be easy to implement the new Skipgram model.\n",
    "However, let us save some time since we already do the neural Ngram Language Model. Furthermore, reimplementing an efficient Skipgram model on a large corpus takes a lot of time and optimization. \n",
    "There are a lot of optimized implementation and tons of papers since the original Word2Vec paper. \n",
    " Hence, we will simply use exsiting library Gensim to train our word embedding. Please read the original Word2Vec paper to review the relationship between above NNLM, SkipGram, CBOW.\n",
    "* https://arxiv.org/abs/1301.3781 \n",
    "* https://github.com/piskvorky/gensim/blob/develop/gensim/models/word2vec.py \n",
    "\n",
    "The word2vec algorithms include skip-gram and CBOW models, using either\n",
    "hierarchical softmax or negative sampling: `Tomas Mikolov et al: Efficient Estimation of Word Representations\n",
    "in Vector Space <https://arxiv.org/pdf/1301.3781.pdf>`_, `Tomas Mikolov et al: Distributed Representations of Words\n",
    "and Phrases and their Compositionality <https://arxiv.org/abs/1310.4546>`_.\n",
    "\n",
    "* Please follow this tutorial of Genism Word2Vec to train embedding with the SST training data, https://radimrehurek.com/gensim/models/word2vec.html \n",
    "* Compare the performance with Section 2.1 and Section 2.2 with given 50d and 300d glove embedding.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs5293-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
